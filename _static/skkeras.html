
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>skkeras package &#8212; scikit-keras 0.1.8 documentation</title>
    <link rel="stylesheet" href="alabaster.css" type="text/css" />
    <link rel="stylesheet" href="pygments.css" type="text/css" />
    <script type="text/javascript" src="documentation_options.js"></script>
    <script type="text/javascript" src="jquery.js"></script>
    <script type="text/javascript" src="underscore.js"></script>
    <script type="text/javascript" src="doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="skkeras-package">
<h1>skkeras package<a class="headerlink" href="#skkeras-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-skkeras.architecture">
<span id="skkeras-architecture-module"></span><h2>skkeras.architecture module<a class="headerlink" href="#module-skkeras.architecture" title="Permalink to this headline">¶</a></h2>
<p>Scikit-learn-compatible Keras model architectures.</p>
<p>&#64;author: David Diaz Vico
&#64;license: MIT</p>
<dl class="class">
<dt id="skkeras.architecture.Straight">
<em class="property">class </em><code class="descclassname">skkeras.architecture.</code><code class="descname">Straight</code><span class="sig-paren">(</span><em>convolution_filters=None</em>, <em>convolution_kernel_size=None</em>, <em>convolution_strides=None</em>, <em>convolution_padding='valid'</em>, <em>convolution_dilation_rate=None</em>, <em>convolution_activation=None</em>, <em>convolution_use_bias=True</em>, <em>convolution_kernel_initializer='glorot_uniform'</em>, <em>convolution_bias_initializer='zeros'</em>, <em>convolution_kernel_constraint=None</em>, <em>convolution_bias_constraint=None</em>, <em>pooling_type='max'</em>, <em>pooling_pool_size=None</em>, <em>pooling_strides=None</em>, <em>pooling_padding='valid'</em>, <em>recurrent_type='lstm'</em>, <em>recurrent_units=None</em>, <em>recurrent_activation='tanh'</em>, <em>recurrent_recurrent_activation='hard_sigmoid'</em>, <em>recurrent_use_bias=True</em>, <em>recurrent_kernel_initializer='glorot_uniform'</em>, <em>recurrent_recurrent_initializer='orthogonal'</em>, <em>recurrent_bias_initializer='zeros'</em>, <em>recurrent_unit_forget_bias=True</em>, <em>recurrent_kernel_constraint=None</em>, <em>recurrent_recurrent_constraint=None</em>, <em>recurrent_bias_constraint=None</em>, <em>recurrent_dropout=0.0</em>, <em>recurrent_recurrent_dropout=0.0</em>, <em>recurrent_return_sequences=False</em>, <em>recurrent_go_backwards=False</em>, <em>recurrent_stateful=False</em>, <em>recurrent_unroll=False</em>, <em>recurrent_implementation=0</em>, <em>batchnormalization=False</em>, <em>batchnormalization_axis=-1</em>, <em>batchnormalization_momentum=0.99</em>, <em>batchnormalization_epsilon=0.001</em>, <em>batchnormalization_center=True</em>, <em>batchnormalization_scale=True</em>, <em>batchnormalization_beta_initializer='zeros'</em>, <em>batchnormalization_gamma_initializer='ones'</em>, <em>batchnormalization_moving_mean_initializer='zeros'</em>, <em>batchnormalization_moving_variance_initializer='ones'</em>, <em>batchnormalization_beta_constraint=None</em>, <em>batchnormalization_gamma_constraint=None</em>, <em>dense_units=None</em>, <em>dense_activation='relu'</em>, <em>dense_use_bias=True</em>, <em>dense_kernel_initializer='he_uniform'</em>, <em>dense_bias_initializer='zeros'</em>, <em>kernel_regularizer_l1=None</em>, <em>kernel_regularizer_l2=None</em>, <em>bias_regularizer_l1=None</em>, <em>bias_regularizer_l2=None</em>, <em>activity_regularizer_l1=None</em>, <em>activity_regularizer_l2=None</em>, <em>recurrent_regularizer_l1=None</em>, <em>recurrent_regularizer_l2=None</em>, <em>beta_regularizer_l1=None</em>, <em>beta_regularizer_l2=None</em>, <em>gamma_regularizer_l1=None</em>, <em>gamma_regularizer_l2=None</em>, <em>dense_kernel_constraint=None</em>, <em>dense_bias_constraint=None</em>, <em>dropout_rate=0.0</em>, <em>dropout_noise_shape=None</em>, <em>dropout_seed=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/architecture.html#Straight"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.architecture.Straight" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Straight feed-forward architecture.</p>
<p>Basic straight feed-forward model architecture.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>convolution_filters</strong> (<em>integer</em><em>, </em><em>default=None</em>) – Dimensionality of the output space.</li>
<li><strong>convolution_kernel_size</strong> (<em>integer/tuple/list</em><em>, </em><em>default=None</em>) – Dimensionality of the convolution window.</li>
<li><strong>convolution_strides</strong> (<em>integer/tuple/list</em><em>, </em><em>default=None</em>) – Strides of the convolution.</li>
<li><strong>convolution_padding</strong> (<em>{&quot;valid&quot;</em><em>, </em><em>&quot;same&quot;}</em><em>, </em><em>default='valid'</em>) – </li>
<li><strong>convolution_dilation_rate</strong> (<em>integer/tuple/list</em><em>, </em><em>default=None</em>) – Dilation rate to use for dilated convolution.</li>
<li><strong>convolution_activation</strong> (<em>string/function</em><em>, </em><em>default=None</em>) – Activation function.</li>
<li><strong>convolution_use_bias</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether the layer uses a bias vector.</li>
<li><strong>convolution_kernel_initializer</strong> (<em>string/function</em><em>, </em><em>default='glorot_uniform'</em>) – Initializer for the kernel weights matrix.</li>
<li><strong>convolution_bias_initializer</strong> (<em>string/function</em><em>, </em><em>default='zeros'</em>) – Initializer for the bias vector.</li>
<li><strong>convolution_kernel_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the kernel
matrix.</li>
<li><strong>convolution_bias_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the bias vector.</li>
<li><strong>pooling_type</strong> (<em>{&quot;max&quot;</em><em>, </em><em>&quot;average}</em><em>, </em><em>default='max'</em>) – </li>
<li><strong>pooling_pool_size</strong> (<em>integer/tuple/list</em><em>, </em><em>default=None</em>) – Factors by which to downscale.</li>
<li><strong>pooling_strides</strong> (<em>integer/tuple/list</em><em>, </em><em>default=None</em>) – Strides values.</li>
<li><strong>pooling_padding</strong> (<em>{&quot;valid&quot;</em><em>, </em><em>&quot;same&quot;}</em><em>, </em><em>default='valid'</em>) – </li>
<li><strong>recurrent_type</strong> (<em>{&quot;lstm&quot;</em><em>, </em><em>&quot;gru&quot;}</em><em>, </em><em>default='lstm'</em>) – </li>
<li><strong>recurrent_units</strong> (<em>integer</em><em>, </em><em>default=None</em>) – Dimensionality of the output space.</li>
<li><strong>recurrent_activation</strong> (<em>string/function</em><em>, </em><em>default='tanh'</em>) – Activation function to use.</li>
<li><strong>recurrent_recurrent_activation</strong> (<em>string/function</em><em>, </em><em>default='hard_sigmoid'</em>) – Activation function to use for the recurrent
step.</li>
<li><strong>recurrent_use_bias</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether the layer uses a bias vector.</li>
<li><strong>recurrent_kernel_initializer</strong> (<em>string/function</em><em>, </em><em>default='glorot_uniform'</em>) – Initializer for the kernel weights matrix.</li>
<li><strong>recurrent_recurrent_initializer</strong> (<em>string/function</em><em>, </em><em>default='orthogonal'</em>) – Initializer for the recurrent_kernel
weights matrix.</li>
<li><strong>recurrent_bias_initializer</strong> (<em>string/function</em><em>, </em><em>default='zeros'</em>) – Initializer for the bias vector.</li>
<li><strong>recurrent_unit_forget_bias</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – If True, add 1 to the bias of the forget gate
at initialization.</li>
<li><strong>recurrent_kernel_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the kernel
weights matrix.</li>
<li><strong>recurrent_recurrent_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the
recurrent_kernel weights matrix.</li>
<li><strong>recurrent_bias_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the bias vector.</li>
<li><strong>recurrent_dropout</strong> (<em>float in</em><em> [</em><em>0</em><em>, </em><em>1</em><em>]</em><em>, </em><em>default=0.0</em>) – Fraction of the units to drop for the linear
transformation of the inputs.</li>
<li><strong>recurrent_recurrent_dropout</strong> (<em>float in</em><em> [</em><em>0</em><em>, </em><em>1</em><em>]</em><em>, </em><em>default=0.0</em>) – Fraction of the units to drop for the linear
transformation of the recurrent state.</li>
<li><strong>recurrent_return_sequences</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – Whether to return the last output in the output
sequence, or the full sequence.</li>
<li><strong>recurrent_go_backwards</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – If True, process the input sequence backwards and
return the reversed sequence.</li>
<li><strong>recurrent_stateful</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – If True, the last state for each sample at index i in a
batch will be used as initial state for the sample of
index i in the following batch.</li>
<li><strong>recurrent_unroll</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – If True, the network will be unrolled, else a symbolic
loop will be used.</li>
<li><strong>recurrent_implementation</strong> (<em>{0</em><em>, </em><em>1</em><em>, </em><em>2}</em><em>, </em><em>default=0</em>) – </li>
<li><strong>batchnormalization</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – Whether to perform batch normalization or not.</li>
<li><strong>batchnormalization_axis</strong> (<em>integer</em><em>, </em><em>default=-1</em>) – The axis that should be normalized (typically the
features axis).</li>
<li><strong>batchnormalization_momentum</strong> (<em>float</em><em>, </em><em>default=0.99</em>) – Momentum for the moving average.</li>
<li><strong>batchnormalization_epsilon</strong> (<em>float</em><em>, </em><em>default=0.001</em>) – Small float added to variance to avoid dividing
by zero.</li>
<li><strong>batchnormalization_center</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – If True, add offset of beta to normalized tensor.
If False, beta is ignored.</li>
<li><strong>batchnormalization_scale</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – If True, multiply by gamma. If False, gamma is not
used.</li>
<li><strong>batchnormalization_beta_initializer</strong> (<em>string/function</em><em>, </em><em>default='zeros'</em>) – Initializer for the beta weight.</li>
<li><strong>batchnormalization_gamma_initializer</strong> (<em>string/function</em><em>, </em><em>default='ones'</em>) – Initializer for the gamma weight.</li>
<li><strong>batchnormalization_moving_mean_initializer</strong> (<em>string/function</em><em>, </em><em>default='zeros'</em>) – Initializer for the moving mean.</li>
<li><strong>batchnormalization_moving_variance_initializer</strong> (<em>string/function</em><em>,</em>) – default=’ones’
Initializer for the moving
variance.</li>
<li><strong>batchnormalization_beta_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Optional constraint for the beta weight.</li>
<li><strong>batchnormalization_gamma_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Optional constraint for the gamma
weight.</li>
<li><strong>dense_units</strong> (<em>integer</em><em>, </em><em>default=None</em>) – Dimensionality of the output space.</li>
<li><strong>dense_activation</strong> (<em>string/function</em><em>, </em><em>default='relu'</em>) – Activation function to use.</li>
<li><strong>dense_use_bias</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether the layer uses a bias vector.</li>
<li><strong>dense_kernel_initializer</strong> (<em>string/function</em><em>, </em><em>default='he_uniform'</em>) – Initializer for the kernel weights matrix.</li>
<li><strong>dense_bias_initializer</strong> (<em>string/function</em><em>, </em><em>default='zeros'</em>) – Initializer for the bias vector.</li>
<li><strong>dense_kernel_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the kernel weights
matrix.</li>
<li><strong>dense_bias_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the bias vector.</li>
<li><strong>dropout_rate</strong> (<em>float in</em><em> [</em><em>0</em><em>, </em><em>1</em><em>]</em><em>, </em><em>default=0.0</em>) – Fraction of the input units to drop.</li>
<li><strong>dropout_noise_shape</strong> (<em>array-like</em><em>, </em><em>default=None</em>) – shape of the binary dropout mask that will be
multiplied with the input.</li>
<li><strong>dropout_seed</strong> (<em>integer</em><em>, </em><em>default=None</em>) – Random seed.</li>
<li><strong>kernel_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the kernel
weights matrix.</li>
<li><strong>kernel_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the kernel
weights matrix.</li>
<li><strong>bias_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the bias vector.</li>
<li><strong>bias_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the bias vector.</li>
<li><strong>activity_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the output of
the layer.</li>
<li><strong>activity_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the output of
the layer.</li>
<li><strong>recurrent_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the
recurrent_kernel weights matrix.</li>
<li><strong>recurrent_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the
recurrent_kernel weights matrix.</li>
<li><strong>beta_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the beta weight.</li>
<li><strong>beta_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the beta weight.</li>
<li><strong>gamma_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the gamma  weight.</li>
<li><strong>gamma_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the gamma  weight.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-skkeras.base">
<span id="skkeras-base-module"></span><h2>skkeras.base module<a class="headerlink" href="#module-skkeras.base" title="Permalink to this headline">¶</a></h2>
<p>Scikit-learn-compatible Keras models.</p>
<p>&#64;author: David Diaz Vico
&#64;license: MIT</p>
<dl class="class">
<dt id="skkeras.base.BaseFeedForward">
<em class="property">class </em><code class="descclassname">skkeras.base.</code><code class="descname">BaseFeedForward</code><span class="sig-paren">(</span><em>architecture=None</em>, <em>activation='linear'</em>, <em>use_bias=True</em>, <em>kernel_initializer='glorot_uniform'</em>, <em>bias_initializer='zeros'</em>, <em>kernel_regularizer_l1=None</em>, <em>kernel_regularizer_l2=None</em>, <em>bias_regularizer_l1=None</em>, <em>bias_regularizer_l2=None</em>, <em>activity_regularizer_l1=None</em>, <em>activity_regularizer_l2=None</em>, <em>kernel_constraint=None</em>, <em>bias_constraint=None</em>, <em>optimizer='adam'</em>, <em>lr=0.001</em>, <em>momentum=0.0</em>, <em>nesterov=False</em>, <em>decay=0.0</em>, <em>rho=0.9</em>, <em>epsilon=1e-08</em>, <em>beta_1=0.9</em>, <em>beta_2=0.999</em>, <em>schedule_decay=0.004</em>, <em>loss='mse'</em>, <em>metrics=None</em>, <em>loss_weights=None</em>, <em>sample_weight_mode=None</em>, <em>batch_size='auto'</em>, <em>epochs=200</em>, <em>verbose=2</em>, <em>early_stopping=True</em>, <em>tol=0.0001</em>, <em>patience=2</em>, <em>validation_split=0.1</em>, <em>validation_data=None</em>, <em>shuffle=True</em>, <em>class_weight=None</em>, <em>sample_weight=None</em>, <em>initial_epoch=0</em>, <em>window=None</em>, <em>return_sequences=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/base.html#BaseFeedForward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.base.BaseFeedForward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.TransformerMixin</span></code></p>
<p>Feed-forward regressor/classifier.</p>
<p>This model optimizes the MSE/categorical-crossentropy function using
back-propagation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>architecture</strong> (<em>keras function</em><em>, </em><em>default=None</em>) – Feature transformation.</li>
<li><strong>activation</strong> (<em>string/function</em><em>, </em><em>default='linear'/'softmax'</em>) – Activation function to use.</li>
<li><strong>use_bias</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether the layer uses a bias vector.</li>
<li><strong>kernel_initializer</strong> (<em>string/function</em><em>, </em><em>default='glorot_uniform'</em>) – Initializer for the kernel weights matrix.</li>
<li><strong>bias_initializer</strong> (<em>string/function</em><em>, </em><em>default='zeros'</em>) – Initializer for the bias vector.</li>
<li><strong>kernel_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the kernel
weights matrix.</li>
<li><strong>kernel_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the kernel
weights matrix.</li>
<li><strong>bias_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the bias vector.</li>
<li><strong>bias_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the bias vector.</li>
<li><strong>activity_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the output of
the layer.</li>
<li><strong>activity_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the output of
the layer.</li>
<li><strong>kernel_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the kernel weights matrix.</li>
<li><strong>bias_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the bias vector.</li>
<li><strong>optimizer</strong> (<em>{&quot;sgd&quot;</em><em>, </em><em>&quot;rmsprop&quot;</em><em>, </em><em>&quot;adagrad&quot;</em><em>, </em><em>&quot;adadelta&quot;</em><em>, </em><em>&quot;adam&quot;</em><em>, </em><em>&quot;adamax&quot;</em><em>,</em>) – “nadam”}, default=’adam’
Optimizer</li>
<li><strong>lr</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.001</em>) – Learning rate.</li>
<li><strong>momentum</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.0</em>) – Parameter updates momentum.</li>
<li><strong>nesterov</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – Whether to apply Nesterov momentum.</li>
<li><strong>decay</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.0</em>) – Learning rate decay over each update.</li>
<li><strong>rho</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.9</em>) – </li>
<li><strong>epsilon</strong> (<em>float&gt;=0</em><em>, </em><em>default=1e-08</em>) – Fuzz factor.</li>
<li><strong>beta_1</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>default=0.9</em>) – </li>
<li><strong>beta_2</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>default=0.999</em>) – </li>
<li><strong>schedule_decay</strong> (<em>, </em><em>default=0.004</em>) – </li>
<li><strong>loss</strong> (<em>string/function</em><em>, </em><em>default='mse'/'categorical_crossentropy'</em>) – Loss function.</li>
<li><strong>metrics</strong> (<em>list</em><em>, </em><em>default=None</em>) – List of metrics to be evaluated by the model during training and
testing.</li>
<li><strong>loss_weights</strong> (<em>list</em><em> or </em><em>dictionary</em><em>, </em><em>default=None</em>) – Scalar coefficients to weight the loss contributions of
different model outputs.</li>
<li><strong>sample_weight_mode</strong> (<em>{&quot;temporal&quot;</em><em>, </em><em>None}</em><em>, </em><em>default=None</em>) – Timestep-wise sample weighting.</li>
<li><strong>batch_size</strong> (<em>integer</em><em>, </em><em>default='auto'</em>) – Number of samples per gradient update.</li>
<li><strong>epochs</strong> (<em>integer</em><em>, </em><em>default=200</em>) – The number of times to iterate over the training data arrays.</li>
<li><strong>verbose</strong> (<em>{0</em><em>, </em><em>1</em><em>, </em><em>2}</em><em>, </em><em>default=2</em>) – Verbosity mode. 0=silent, 1=verbose, 2=one log line per epoch.</li>
<li><strong>early_stopping</strong> (<em>bool</em><em>, </em><em>default True</em>) – Whether to use early stopping to terminate training when
validation score is not improving.</li>
<li><strong>tol</strong> (<em>float</em><em>, </em><em>default 1e-4</em>) – Tolerance for the optimization.</li>
<li><strong>patience</strong> (<em>integer</em><em>, </em><em>default 2</em>) – Number of epochs with no improvement after which training will
be stopped.</li>
<li><strong>validation_split</strong> (<em>float in</em><em> [</em><em>0</em><em>, </em><em>1</em><em>]</em><em>, </em><em>default=0.1</em>) – Fraction of the training data to be used as validation
data.</li>
<li><strong>validation_data</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>(</em><em>n_samples</em><em>, </em><em>features_shape</em><em>)</em><em>,</em>) – (n_samples, targets_shape)),
default=None
Data on which to evaluate the loss and any model metrics at
the end of each epoch.</li>
<li><strong>shuffle</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether to shuffle the training data before each epoch.</li>
<li><strong>class_weight</strong> (<em>dictionary</em><em>, </em><em>default=None</em>) – class indices to weights to apply to the model’s loss for the
samples from each class during training.</li>
<li><strong>sample_weight</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>)</em><em>, </em><em>default=None</em>) – Weights to apply to the model’s loss for each sample.</li>
<li><strong>initial_epoch</strong> (<em>integer</em><em>, </em><em>default=0</em>) – Epoch at which to start training.</li>
<li><strong>window</strong> (<em>integer</em><em>, </em><em>default=None</em>) – Time window length.</li>
<li><strong>return_sequences</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – Whether to return the last output in the output sequence,
or the full sequence.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="skkeras.base.BaseFeedForward.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>optimizer=None</em>, <em>lr=None</em>, <em>momentum=None</em>, <em>nesterov=None</em>, <em>decay=None</em>, <em>rho=None</em>, <em>epsilon=None</em>, <em>beta_1=None</em>, <em>beta_2=None</em>, <em>schedule_decay=None</em>, <em>loss=None</em>, <em>metrics=None</em>, <em>loss_weights=None</em>, <em>sample_weight_mode=None</em>, <em>batch_size=None</em>, <em>epochs=None</em>, <em>verbose=None</em>, <em>early_stopping=None</em>, <em>tol=None</em>, <em>patience=None</em>, <em>validation_split=None</em>, <em>validation_data=None</em>, <em>shuffle=None</em>, <em>class_weight=None</em>, <em>sample_weight=None</em>, <em>initial_epoch=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/base.html#BaseFeedForward.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.base.BaseFeedForward.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data.</p>
<p>Fit model to X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</li>
<li><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</li>
<li><strong>optimizer</strong> (<em>{&quot;sgd&quot;</em><em>, </em><em>&quot;rmsprop&quot;</em><em>, </em><em>&quot;adagrad&quot;</em><em>, </em><em>&quot;adadelta&quot;</em><em>, </em><em>&quot;adam&quot;</em><em>, </em><em>&quot;adamax&quot;</em><em>,</em>) – “nadam”}, default=’adam’
Optimizer</li>
<li><strong>lr</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.001</em>) – Learning rate.</li>
<li><strong>momentum</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.0</em>) – Parameter updates momentum.</li>
<li><strong>nesterov</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – Whether to apply Nesterov momentum.</li>
<li><strong>decay</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.0</em>) – Learning rate decay over each update.</li>
<li><strong>rho</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.9</em>) – </li>
<li><strong>epsilon</strong> (<em>float&gt;=0</em><em>, </em><em>default=1e-08</em>) – Fuzz factor.</li>
<li><strong>beta_1</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>default=0.9</em>) – </li>
<li><strong>beta_2</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>default=0.999</em>) – </li>
<li><strong>schedule_decay</strong> (<em>, </em><em>default=0.004</em>) – </li>
<li><strong>loss</strong> (<em>string/function</em><em>, </em><em>default='mse'/'categorical_crossentropy'</em>) – Loss function.</li>
<li><strong>metrics</strong> (<em>list</em><em>, </em><em>default=None</em>) – List of metrics to be evaluated by the model during training
and testing.</li>
<li><strong>loss_weights</strong> (<em>list</em><em> or </em><em>dictionary</em><em>, </em><em>default=None</em>) – Scalar coefficients to weight the loss contributions of
different model outputs.</li>
<li><strong>sample_weight_mode</strong> (<em>{&quot;temporal&quot;</em><em>, </em><em>None}</em><em>, </em><em>default=None</em>) – Timestep-wise sample weighting.</li>
<li><strong>batch_size</strong> (<em>integer</em><em>, </em><em>default='auto'</em>) – Number of samples per gradient update.</li>
<li><strong>epochs</strong> (<em>integer</em><em>, </em><em>default=200</em>) – The number of times to iterate over the training data arrays.</li>
<li><strong>verbose</strong> (<em>{0</em><em>, </em><em>1</em><em>, </em><em>2}</em><em>, </em><em>default=1</em>) – Verbosity mode. 0=silent, 1=verbose, 2=one log line per epoch.</li>
<li><strong>early_stopping</strong> (<em>bool</em><em>, </em><em>default True</em>) – Whether to use early stopping to terminate training
when validation score is not improving.</li>
<li><strong>tol</strong> (<em>float</em><em>, </em><em>default 1e-4</em>) – Tolerance for the optimization.</li>
<li><strong>patience</strong> (<em>integer</em><em>, </em><em>default 2</em>) – Number of epochs with no improvement after which training will
be stopped.</li>
<li><strong>validation_split</strong> (<em>float in</em><em> [</em><em>0</em><em>, </em><em>1</em><em>]</em><em>, </em><em>default=0.1</em>) – Fraction of the training data to be used as validation
data.</li>
<li><strong>validation_data</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>(</em><em>n_samples</em><em>, </em><em>features_shape</em><em>)</em><em>,</em>) – (n_samples, targets_shape)),
default=None
Data on which to evaluate the loss and any model
metrics at the end of each epoch.</li>
<li><strong>shuffle</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether to shuffle the training data before each epoch.</li>
<li><strong>class_weight</strong> (<em>dictionary</em><em>, </em><em>default=None</em>) – class indices to weights to apply to the model’s loss for
the samples from each class during training.</li>
<li><strong>sample_weight</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>)</em><em>, </em><em>default=None</em>) – Weights to apply to the model’s loss for each sample.</li>
<li><strong>initial_epoch</strong> (<em>integer</em><em>, </em><em>default=0</em>) – Epoch at which to start training.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="skkeras.base.BaseFeedForward.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>batch_size=32</em>, <em>verbose=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/base.html#BaseFeedForward.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.base.BaseFeedForward.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict using the trained model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>features_shape</em><em>)</em>) – The input data.</li>
<li><strong>batch_size</strong> (<em>integer</em><em>, </em><em>default=32</em>) – Batch size.</li>
<li><strong>verbose</strong> (<em>{0</em><em>, </em><em>1}</em><em>, </em><em>default=0</em>) – Verbosity mode.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong> – Target predictions for X.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape (n_samples, targets_shape)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="skkeras.base.BaseFeedForward.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>metric=&lt;function r2_score&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/base.html#BaseFeedForward.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.base.BaseFeedForward.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the score of the model on the data X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>features_shape</em><em>)</em>) – Test samples.</li>
<li><strong>y</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>targets_shape</em><em>)</em>) – Targets for X.</li>
<li><strong>sample_weight</strong> (<em>array-like</em><em>, </em><em>shape</em><em> [</em><em>n_samples</em><em>]</em><em>, </em><em>default=None</em>) – Sample weights.</li>
<li><strong>metric</strong> (<em>function</em><em>, </em><em>default=r2_score/accuracy_score</em>) – Metric to be evaluated.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> – r2_score/accuracy of self.predict(X) wrt. y.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="skkeras.base.BaseFeedForward.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/base.html#BaseFeedForward.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.base.BaseFeedForward.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform using the trained model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>features_shape</em><em>)</em>) – The input data.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>Z</strong> – Transformations for X.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">array-like, shape (n_samples, last_hidden_layer_shape)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="skkeras.base.FFClassifier">
<em class="property">class </em><code class="descclassname">skkeras.base.</code><code class="descname">FFClassifier</code><span class="sig-paren">(</span><em>architecture=None</em>, <em>*</em>, <em>activation='softmax'</em>, <em>use_bias=True</em>, <em>kernel_initializer='glorot_uniform'</em>, <em>bias_initializer='zeros'</em>, <em>kernel_regularizer_l1=None</em>, <em>kernel_regularizer_l2=None</em>, <em>bias_regularizer_l1=None</em>, <em>bias_regularizer_l2=None</em>, <em>activity_regularizer_l1=None</em>, <em>activity_regularizer_l2=None</em>, <em>kernel_constraint=None</em>, <em>bias_constraint=None</em>, <em>optimizer='adam'</em>, <em>lr=0.001</em>, <em>momentum=0.0</em>, <em>nesterov=False</em>, <em>decay=0.0</em>, <em>rho=0.9</em>, <em>epsilon=1e-08</em>, <em>beta_1=0.9</em>, <em>beta_2=0.999</em>, <em>schedule_decay=0.004</em>, <em>loss='categorical_crossentropy'</em>, <em>metrics=None</em>, <em>loss_weights=None</em>, <em>sample_weight_mode=None</em>, <em>batch_size='auto'</em>, <em>epochs=200</em>, <em>verbose=2</em>, <em>early_stopping=True</em>, <em>tol=0.0001</em>, <em>patience=2</em>, <em>validation_split=0.1</em>, <em>validation_data=None</em>, <em>shuffle=True</em>, <em>class_weight=None</em>, <em>sample_weight=None</em>, <em>initial_epoch=0</em>, <em>window=None</em>, <em>return_sequences=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/base.html#FFClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.base.FFClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#skkeras.base.BaseFeedForward" title="skkeras.base.BaseFeedForward"><code class="xref py py-class docutils literal notranslate"><span class="pre">skkeras.base.BaseFeedForward</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.ClassifierMixin</span></code></p>
<p>Feed-forward regressor/classifier.</p>
<p>This model optimizes the MSE/categorical-crossentropy function using
back-propagation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>architecture</strong> (<em>keras function</em><em>, </em><em>default=None</em>) – Feature transformation.</li>
<li><strong>activation</strong> (<em>string/function</em><em>, </em><em>default='linear'/'softmax'</em>) – Activation function to use.</li>
<li><strong>use_bias</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether the layer uses a bias vector.</li>
<li><strong>kernel_initializer</strong> (<em>string/function</em><em>, </em><em>default='glorot_uniform'</em>) – Initializer for the kernel weights matrix.</li>
<li><strong>bias_initializer</strong> (<em>string/function</em><em>, </em><em>default='zeros'</em>) – Initializer for the bias vector.</li>
<li><strong>kernel_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the kernel
weights matrix.</li>
<li><strong>kernel_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the kernel
weights matrix.</li>
<li><strong>bias_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the bias vector.</li>
<li><strong>bias_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the bias vector.</li>
<li><strong>activity_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the output of
the layer.</li>
<li><strong>activity_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the output of
the layer.</li>
<li><strong>kernel_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the kernel weights matrix.</li>
<li><strong>bias_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the bias vector.</li>
<li><strong>optimizer</strong> (<em>{&quot;sgd&quot;</em><em>, </em><em>&quot;rmsprop&quot;</em><em>, </em><em>&quot;adagrad&quot;</em><em>, </em><em>&quot;adadelta&quot;</em><em>, </em><em>&quot;adam&quot;</em><em>, </em><em>&quot;adamax&quot;</em><em>,</em>) – “nadam”}, default=’adam’
Optimizer</li>
<li><strong>lr</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.001</em>) – Learning rate.</li>
<li><strong>momentum</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.0</em>) – Parameter updates momentum.</li>
<li><strong>nesterov</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – Whether to apply Nesterov momentum.</li>
<li><strong>decay</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.0</em>) – Learning rate decay over each update.</li>
<li><strong>rho</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.9</em>) – </li>
<li><strong>epsilon</strong> (<em>float&gt;=0</em><em>, </em><em>default=1e-08</em>) – Fuzz factor.</li>
<li><strong>beta_1</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>default=0.9</em>) – </li>
<li><strong>beta_2</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>default=0.999</em>) – </li>
<li><strong>schedule_decay</strong> (<em>, </em><em>default=0.004</em>) – </li>
<li><strong>loss</strong> (<em>string/function</em><em>, </em><em>default='mse'/'categorical_crossentropy'</em>) – Loss function.</li>
<li><strong>metrics</strong> (<em>list</em><em>, </em><em>default=None</em>) – List of metrics to be evaluated by the model during training and
testing.</li>
<li><strong>loss_weights</strong> (<em>list</em><em> or </em><em>dictionary</em><em>, </em><em>default=None</em>) – Scalar coefficients to weight the loss contributions of
different model outputs.</li>
<li><strong>sample_weight_mode</strong> (<em>{&quot;temporal&quot;</em><em>, </em><em>None}</em><em>, </em><em>default=None</em>) – Timestep-wise sample weighting.</li>
<li><strong>batch_size</strong> (<em>integer</em><em>, </em><em>default='auto'</em>) – Number of samples per gradient update.</li>
<li><strong>epochs</strong> (<em>integer</em><em>, </em><em>default=200</em>) – The number of times to iterate over the training data arrays.</li>
<li><strong>verbose</strong> (<em>{0</em><em>, </em><em>1</em><em>, </em><em>2}</em><em>, </em><em>default=2</em>) – Verbosity mode. 0=silent, 1=verbose, 2=one log line per epoch.</li>
<li><strong>early_stopping</strong> (<em>bool</em><em>, </em><em>default True</em>) – Whether to use early stopping to terminate training when
validation score is not improving.</li>
<li><strong>tol</strong> (<em>float</em><em>, </em><em>default 1e-4</em>) – Tolerance for the optimization.</li>
<li><strong>patience</strong> (<em>integer</em><em>, </em><em>default 2</em>) – Number of epochs with no improvement after which training will
be stopped.</li>
<li><strong>validation_split</strong> (<em>float in</em><em> [</em><em>0</em><em>, </em><em>1</em><em>]</em><em>, </em><em>default=0.1</em>) – Fraction of the training data to be used as validation
data.</li>
<li><strong>validation_data</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>(</em><em>n_samples</em><em>, </em><em>features_shape</em><em>)</em><em>,</em>) – (n_samples, targets_shape)),
default=None
Data on which to evaluate the loss and any model metrics at
the end of each epoch.</li>
<li><strong>shuffle</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether to shuffle the training data before each epoch.</li>
<li><strong>class_weight</strong> (<em>dictionary</em><em>, </em><em>default=None</em>) – class indices to weights to apply to the model’s loss for the
samples from each class during training.</li>
<li><strong>sample_weight</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>)</em><em>, </em><em>default=None</em>) – Weights to apply to the model’s loss for each sample.</li>
<li><strong>initial_epoch</strong> (<em>integer</em><em>, </em><em>default=0</em>) – Epoch at which to start training.</li>
<li><strong>window</strong> (<em>integer</em><em>, </em><em>default=None</em>) – Time window length.</li>
<li><strong>return_sequences</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – Whether to return the last output in the output sequence,
or the full sequence.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="skkeras.base.FFClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/base.html#FFClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.base.FFClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data.</p>
<p>Fit model to X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</li>
<li><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</li>
<li><strong>optimizer</strong> (<em>{&quot;sgd&quot;</em><em>, </em><em>&quot;rmsprop&quot;</em><em>, </em><em>&quot;adagrad&quot;</em><em>, </em><em>&quot;adadelta&quot;</em><em>, </em><em>&quot;adam&quot;</em><em>, </em><em>&quot;adamax&quot;</em><em>,</em>) – “nadam”}, default=’adam’
Optimizer</li>
<li><strong>lr</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.001</em>) – Learning rate.</li>
<li><strong>momentum</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.0</em>) – Parameter updates momentum.</li>
<li><strong>nesterov</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – Whether to apply Nesterov momentum.</li>
<li><strong>decay</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.0</em>) – Learning rate decay over each update.</li>
<li><strong>rho</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.9</em>) – </li>
<li><strong>epsilon</strong> (<em>float&gt;=0</em><em>, </em><em>default=1e-08</em>) – Fuzz factor.</li>
<li><strong>beta_1</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>default=0.9</em>) – </li>
<li><strong>beta_2</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>default=0.999</em>) – </li>
<li><strong>schedule_decay</strong> (<em>, </em><em>default=0.004</em>) – </li>
<li><strong>loss</strong> (<em>string/function</em><em>, </em><em>default='mse'/'categorical_crossentropy'</em>) – Loss function.</li>
<li><strong>metrics</strong> (<em>list</em><em>, </em><em>default=None</em>) – List of metrics to be evaluated by the model during training
and testing.</li>
<li><strong>loss_weights</strong> (<em>list</em><em> or </em><em>dictionary</em><em>, </em><em>default=None</em>) – Scalar coefficients to weight the loss contributions of
different model outputs.</li>
<li><strong>sample_weight_mode</strong> (<em>{&quot;temporal&quot;</em><em>, </em><em>None}</em><em>, </em><em>default=None</em>) – Timestep-wise sample weighting.</li>
<li><strong>batch_size</strong> (<em>integer</em><em>, </em><em>default='auto'</em>) – Number of samples per gradient update.</li>
<li><strong>epochs</strong> (<em>integer</em><em>, </em><em>default=200</em>) – The number of times to iterate over the training data arrays.</li>
<li><strong>verbose</strong> (<em>{0</em><em>, </em><em>1</em><em>, </em><em>2}</em><em>, </em><em>default=1</em>) – Verbosity mode. 0=silent, 1=verbose, 2=one log line per epoch.</li>
<li><strong>early_stopping</strong> (<em>bool</em><em>, </em><em>default True</em>) – Whether to use early stopping to terminate training
when validation score is not improving.</li>
<li><strong>tol</strong> (<em>float</em><em>, </em><em>default 1e-4</em>) – Tolerance for the optimization.</li>
<li><strong>patience</strong> (<em>integer</em><em>, </em><em>default 2</em>) – Number of epochs with no improvement after which training will
be stopped.</li>
<li><strong>validation_split</strong> (<em>float in</em><em> [</em><em>0</em><em>, </em><em>1</em><em>]</em><em>, </em><em>default=0.1</em>) – Fraction of the training data to be used as validation
data.</li>
<li><strong>validation_data</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>(</em><em>n_samples</em><em>, </em><em>features_shape</em><em>)</em><em>,</em>) – (n_samples, targets_shape)),
default=None
Data on which to evaluate the loss and any model
metrics at the end of each epoch.</li>
<li><strong>shuffle</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether to shuffle the training data before each epoch.</li>
<li><strong>class_weight</strong> (<em>dictionary</em><em>, </em><em>default=None</em>) – class indices to weights to apply to the model’s loss for
the samples from each class during training.</li>
<li><strong>sample_weight</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>)</em><em>, </em><em>default=None</em>) – Weights to apply to the model’s loss for each sample.</li>
<li><strong>initial_epoch</strong> (<em>integer</em><em>, </em><em>default=0</em>) – Epoch at which to start training.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="skkeras.base.FFClassifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/base.html#FFClassifier.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.base.FFClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict using the trained model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>features_shape</em><em>)</em>) – The input data.</li>
<li><strong>batch_size</strong> (<em>integer</em><em>, </em><em>default=32</em>) – Batch size.</li>
<li><strong>verbose</strong> (<em>{0</em><em>, </em><em>1}</em><em>, </em><em>default=0</em>) – Verbosity mode.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong> – Target predictions for X.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape (n_samples, targets_shape)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="skkeras.base.FFClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>batch_size=32</em>, <em>verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#skkeras.base.FFClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict using the trained model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>features_shape</em><em>)</em>) – The input data.</li>
<li><strong>batch_size</strong> (<em>integer</em><em>, </em><em>default=32</em>) – Batch size.</li>
<li><strong>verbose</strong> (<em>{0</em><em>, </em><em>1}</em><em>, </em><em>default=0</em>) – Verbosity mode.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong> – Target predictions for X.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape (n_samples, targets_shape)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="skkeras.base.FFClassifier.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>*</em>, <em>metric=&lt;function accuracy_score&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#skkeras.base.FFClassifier.score" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="skkeras.base.FFRegressor">
<em class="property">class </em><code class="descclassname">skkeras.base.</code><code class="descname">FFRegressor</code><span class="sig-paren">(</span><em>architecture=None</em>, <em>activation='linear'</em>, <em>use_bias=True</em>, <em>kernel_initializer='glorot_uniform'</em>, <em>bias_initializer='zeros'</em>, <em>kernel_regularizer_l1=None</em>, <em>kernel_regularizer_l2=None</em>, <em>bias_regularizer_l1=None</em>, <em>bias_regularizer_l2=None</em>, <em>activity_regularizer_l1=None</em>, <em>activity_regularizer_l2=None</em>, <em>kernel_constraint=None</em>, <em>bias_constraint=None</em>, <em>optimizer='adam'</em>, <em>lr=0.001</em>, <em>momentum=0.0</em>, <em>nesterov=False</em>, <em>decay=0.0</em>, <em>rho=0.9</em>, <em>epsilon=1e-08</em>, <em>beta_1=0.9</em>, <em>beta_2=0.999</em>, <em>schedule_decay=0.004</em>, <em>loss='mse'</em>, <em>metrics=None</em>, <em>loss_weights=None</em>, <em>sample_weight_mode=None</em>, <em>batch_size='auto'</em>, <em>epochs=200</em>, <em>verbose=2</em>, <em>early_stopping=True</em>, <em>tol=0.0001</em>, <em>patience=2</em>, <em>validation_split=0.1</em>, <em>validation_data=None</em>, <em>shuffle=True</em>, <em>class_weight=None</em>, <em>sample_weight=None</em>, <em>initial_epoch=0</em>, <em>window=None</em>, <em>return_sequences=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/base.html#FFRegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.base.FFRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#skkeras.base.BaseFeedForward" title="skkeras.base.BaseFeedForward"><code class="xref py py-class docutils literal notranslate"><span class="pre">skkeras.base.BaseFeedForward</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.RegressorMixin</span></code></p>
<p>Feed-forward regressor/classifier.</p>
<p>This model optimizes the MSE/categorical-crossentropy function using
back-propagation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>architecture</strong> (<em>keras function</em><em>, </em><em>default=None</em>) – Feature transformation.</li>
<li><strong>activation</strong> (<em>string/function</em><em>, </em><em>default='linear'/'softmax'</em>) – Activation function to use.</li>
<li><strong>use_bias</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether the layer uses a bias vector.</li>
<li><strong>kernel_initializer</strong> (<em>string/function</em><em>, </em><em>default='glorot_uniform'</em>) – Initializer for the kernel weights matrix.</li>
<li><strong>bias_initializer</strong> (<em>string/function</em><em>, </em><em>default='zeros'</em>) – Initializer for the bias vector.</li>
<li><strong>kernel_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the kernel
weights matrix.</li>
<li><strong>kernel_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the kernel
weights matrix.</li>
<li><strong>bias_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the bias vector.</li>
<li><strong>bias_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the bias vector.</li>
<li><strong>activity_regularizer_l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor applied to the output of
the layer.</li>
<li><strong>activity_regularizer_l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor applied to the output of
the layer.</li>
<li><strong>kernel_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the kernel weights matrix.</li>
<li><strong>bias_constraint</strong> (<em>function</em><em>, </em><em>default=None</em>) – Constraint function applied to the bias vector.</li>
<li><strong>optimizer</strong> (<em>{&quot;sgd&quot;</em><em>, </em><em>&quot;rmsprop&quot;</em><em>, </em><em>&quot;adagrad&quot;</em><em>, </em><em>&quot;adadelta&quot;</em><em>, </em><em>&quot;adam&quot;</em><em>, </em><em>&quot;adamax&quot;</em><em>,</em>) – “nadam”}, default=’adam’
Optimizer</li>
<li><strong>lr</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.001</em>) – Learning rate.</li>
<li><strong>momentum</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.0</em>) – Parameter updates momentum.</li>
<li><strong>nesterov</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – Whether to apply Nesterov momentum.</li>
<li><strong>decay</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.0</em>) – Learning rate decay over each update.</li>
<li><strong>rho</strong> (<em>float&gt;=0</em><em>, </em><em>default=0.9</em>) – </li>
<li><strong>epsilon</strong> (<em>float&gt;=0</em><em>, </em><em>default=1e-08</em>) – Fuzz factor.</li>
<li><strong>beta_1</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>default=0.9</em>) – </li>
<li><strong>beta_2</strong> (<em>float in</em><em> (</em><em>0</em><em>, </em><em>1</em><em>)</em><em>, </em><em>default=0.999</em>) – </li>
<li><strong>schedule_decay</strong> (<em>, </em><em>default=0.004</em>) – </li>
<li><strong>loss</strong> (<em>string/function</em><em>, </em><em>default='mse'/'categorical_crossentropy'</em>) – Loss function.</li>
<li><strong>metrics</strong> (<em>list</em><em>, </em><em>default=None</em>) – List of metrics to be evaluated by the model during training and
testing.</li>
<li><strong>loss_weights</strong> (<em>list</em><em> or </em><em>dictionary</em><em>, </em><em>default=None</em>) – Scalar coefficients to weight the loss contributions of
different model outputs.</li>
<li><strong>sample_weight_mode</strong> (<em>{&quot;temporal&quot;</em><em>, </em><em>None}</em><em>, </em><em>default=None</em>) – Timestep-wise sample weighting.</li>
<li><strong>batch_size</strong> (<em>integer</em><em>, </em><em>default='auto'</em>) – Number of samples per gradient update.</li>
<li><strong>epochs</strong> (<em>integer</em><em>, </em><em>default=200</em>) – The number of times to iterate over the training data arrays.</li>
<li><strong>verbose</strong> (<em>{0</em><em>, </em><em>1</em><em>, </em><em>2}</em><em>, </em><em>default=2</em>) – Verbosity mode. 0=silent, 1=verbose, 2=one log line per epoch.</li>
<li><strong>early_stopping</strong> (<em>bool</em><em>, </em><em>default True</em>) – Whether to use early stopping to terminate training when
validation score is not improving.</li>
<li><strong>tol</strong> (<em>float</em><em>, </em><em>default 1e-4</em>) – Tolerance for the optimization.</li>
<li><strong>patience</strong> (<em>integer</em><em>, </em><em>default 2</em>) – Number of epochs with no improvement after which training will
be stopped.</li>
<li><strong>validation_split</strong> (<em>float in</em><em> [</em><em>0</em><em>, </em><em>1</em><em>]</em><em>, </em><em>default=0.1</em>) – Fraction of the training data to be used as validation
data.</li>
<li><strong>validation_data</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>(</em><em>n_samples</em><em>, </em><em>features_shape</em><em>)</em><em>,</em>) – (n_samples, targets_shape)),
default=None
Data on which to evaluate the loss and any model metrics at
the end of each epoch.</li>
<li><strong>shuffle</strong> (<em>boolean</em><em>, </em><em>default=True</em>) – Whether to shuffle the training data before each epoch.</li>
<li><strong>class_weight</strong> (<em>dictionary</em><em>, </em><em>default=None</em>) – class indices to weights to apply to the model’s loss for the
samples from each class during training.</li>
<li><strong>sample_weight</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>)</em><em>, </em><em>default=None</em>) – Weights to apply to the model’s loss for each sample.</li>
<li><strong>initial_epoch</strong> (<em>integer</em><em>, </em><em>default=0</em>) – Epoch at which to start training.</li>
<li><strong>window</strong> (<em>integer</em><em>, </em><em>default=None</em>) – Time window length.</li>
<li><strong>return_sequences</strong> (<em>boolean</em><em>, </em><em>default=False</em>) – Whether to return the last output in the output sequence,
or the full sequence.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="skkeras.base.regularize">
<code class="descclassname">skkeras.base.</code><code class="descname">regularize</code><span class="sig-paren">(</span><em>l1=None</em>, <em>l2=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/skkeras/base.html#regularize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#skkeras.base.regularize" title="Permalink to this definition">¶</a></dt>
<dd><p>Regularizer.</p>
<p>Returns a regularizer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>l1</strong> (<em>float</em><em>, </em><em>default=None</em>) – L1 regularization factor.</li>
<li><strong>l2</strong> (<em>float</em><em>, </em><em>default=None</em>) – L2 regularization factor.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Regularizer.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-skkeras">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-skkeras" title="Permalink to this headline">¶</a></h2>
<p>Scikit-learn-compatible Keras models.</p>
<p>&#64;author: David Diaz Vico
&#64;license: MIT</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">skkeras package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-skkeras.architecture">skkeras.architecture module</a></li>
<li><a class="reference internal" href="#module-skkeras.base">skkeras.base module</a></li>
<li><a class="reference internal" href="#module-skkeras">Module contents</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/_static/skkeras.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, David Diaz Vico.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.7.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="../_sources/_static/skkeras.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>